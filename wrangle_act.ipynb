{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from TSV\n",
    "df_image_predictions = pd.read_csv('image-predictions.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather data from twitter \n",
    "# Twittter App Credentials\n",
    "consumer_key = \"A0lPFhv6c1twbEz8BY4r4TfOb\"\n",
    "consumer_secret = \"zQXzmROzedXF9UaoV18siNc7ftNhXMrBXK8uAC4F54fdDfWbbh\"\n",
    "access_token = \"1179780108988477440-5DySAvAMwAemnn5UmvXsFIJW3It8Av\"\n",
    "access_secret = \"k8dQUxpIdLAuWeWzBYtP3xYfumvkjbmNynDCG7CEjVNQW\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id_list = df_archive['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(\"started\")\n",
    "\n",
    "df_list = []\n",
    "for tweet_id in tweet_id_list:\n",
    "    try:\n",
    "        result = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        retweet_count = result['retweet_count']\n",
    "        favorite_count = result['favorite_count']\n",
    "        df_list.append({'tweet_id': tweet_id, 'retweet_count' : retweet_count, 'favorite_count': favorite_count})\n",
    "    except Exception as e:\n",
    "        print (tweet_id)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only certain tweet elements in dataframe\n",
    "elements_to_save = ['id', 'favorite_count', 'retweet_count']\n",
    "\n",
    "data = []\n",
    "\n",
    "with open('tweet_json.txt', 'r') as readfile:\n",
    "    \n",
    "    tweet_json = readfile.readline()\n",
    "    \n",
    "    while tweet_json:\n",
    "        tweet_dict = json.loads(tweet_json)\n",
    "\n",
    "        data_row = dict((k, tweet_dict[k]) for k in elements_to_save)\n",
    "        \n",
    "        data.append(data_row)\n",
    "        \n",
    "        tweet_json = readfile.readline()\n",
    "        \n",
    "            \n",
    "    \n",
    "df_tweet = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "We now have altogether 3 datasets:\n",
    "- **df_tweet**- Dataframe with retweet and favorite count\n",
    "- **df_image_predictions**- Dataframe with image prediction data\n",
    "- **df_archive** - Dataframe with archived tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** \n",
    "\n",
    "Issue:\n",
    "- There are names such as \"a\",\"an\",\"the\" which is very unlikely to be a dog's name.\n",
    "- Datatype correction is needed (timestamp is shown as object)\n",
    "- Some entries are retweets (we need to avoid those)\n",
    "- Some missing values\n",
    "\n",
    "Tidiness:\n",
    "- Four columns (doggo, floofer, pupper, and puppo) can be made into one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_tweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Issues:\n",
    "- There are some missing data as df_archive have total 2356 rows but df_tweet only has 2331 rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Issues: \n",
    "- There are some missing data as df_archive has in total 2356 rows but df_image_predictions only has 2075 rows. \n",
    "- There also seems to be an inconsistency with the casing for p1,p1,p3 (some are titlecase, some lowercase, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data\n",
    "\n",
    "We will be cleaning the data and merging it to make a final dataset to perform our analysis.\n",
    "\n",
    "Tidiness:\n",
    "- We will get rid of data columns related to retweets as we are ignoring retweets.\n",
    "\n",
    "**df_twitter_master** : This Dataframe will store the final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master = df_archive.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_archive\n",
    "\n",
    "#### removing the dog name \"a\", \"an\" and \"the\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_names(row):\n",
    "    if (row['name'] == 'a') or (row['name'] == 'an') or (row['name'] == 'the'):        \n",
    "        #finding the name to replace with a or an or the        \n",
    "        text = row['text']\n",
    "        word_list = text.split()\n",
    "        name = 'None'\n",
    "        # get name from 'named {}'\n",
    "        if 'named' in word_list:\n",
    "            name_pos = word_list.index('named') + 1\n",
    "            name = word_list[name_pos]\n",
    "        # get name from 'name is {}'\n",
    "        elif 'name is' in text:\n",
    "            # Get the next word after 'name is' (skip 'is')\n",
    "            name_pos = word_list.index('name') + 2\n",
    "            name = word_list[name_pos]\n",
    "        #only replace the 'name' column\n",
    "        row['name'] = name.replace('.','')\n",
    "        # Return row whether updated or name\n",
    "    return row\n",
    "    \n",
    "\n",
    "df_twitter_master  = df_twitter_master.apply(replace_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "The dog name in the data is cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting the timestamp\n",
    "\n",
    "df_twitter_master.timestamp = pd.to_datetime(df_twitter_master.timestamp)\n",
    "\n",
    "df_twitter_master.retweeted_status_timestamp = pd.to_datetime(df_twitter_master.retweeted_status_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "The timestamp datatype is fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning data that are retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the retweets \n",
    "retweets = df_twitter_master.text.str.match('^RT @')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Getting rid of retweets\n",
    "df_twitter_master = df_twitter_master[~retweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = df_twitter_master.text.str.match('^RT @')\n",
    "\n",
    "df_twitter_master[retweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the columns into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column\n",
    "df_twitter_master['dog_stage'] = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine all the columns\n",
    "def get_dog_stage(row):\n",
    "    dog_stage = []\n",
    "    \n",
    "    if row['doggo'] == 'doggo':\n",
    "        dog_stage.append('doggo')\n",
    "    if row['floofer'] == 'floofer':\n",
    "        dog_stage.append('floofer')\n",
    "    if row['pupper'] == 'pupper':\n",
    "        dog_stage.append('pupper')\n",
    "    if row['puppo'] == 'puppo':\n",
    "        dog_stage.append('puppo')\n",
    "        \n",
    "    if len(dog_stage) < 1: \n",
    "        row['dog_stage'] = 'None'\n",
    "    else: \n",
    "        row['dog_stage'] = ','.join(dog_stage)\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master = df_twitter_master.apply(get_dog_stage, axis=1)\n",
    "\n",
    "# Drop the redundant columns\n",
    "df_twitter_master =df_twitter_master.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "We have combined all the four columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the missing data issue by combining the df_tweet with df_twitter_master and only keeping the data that is in both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.rename(columns={'id':'tweet_id'}, inplace=True)\n",
    "\n",
    "df_twitter_master = pd.merge(df_twitter_master, df_tweet, how='left', on=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "We have got rid of the missing data from df_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_image_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the missing data issue by combining the df_image_predictions with df_twitter_master and only keeping the data that is in both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.rename(columns={'id':'tweet_id'}, inplace=True)\n",
    "\n",
    "df_twitter_master = pd.merge(df_twitter_master, df_image_predictions, how='left', on=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "We have got rid of the missing data from df_image_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert case to lower to maintain the consistency in p1,p2,p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master['p1'] = df_twitter_master['p1'].str.lower()\n",
    "df_twitter_master['p2'] = df_twitter_master['p2'].str.lower()\n",
    "df_twitter_master['p3'] = df_twitter_master['p3'].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master[['p1','p2','p3']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : We have made the case consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_twitter_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that relate to retweet  \n",
    "retweet_cols = ['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp']\n",
    "df_twitter_master = df_twitter_master.drop(retweet_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataset as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_master.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we tweet the post of our dog, how many favourite count can we expect?\n",
    "\n",
    "df_twitter_master.hist(column='favorite_count', bins=20, range=(0,80000));\n",
    "plt.title('Favorite count')\n",
    "plt.xlabel('Favorites')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : \n",
    "Seems like most of the tweets gets around 0 to 10000 and only few tweets seems to break that boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we tweet the post of our dog, how many retweets are we most likely to get?\n",
    "\n",
    "df_twitter_master.hist(column='retweet_count', bins=25, range=(0,25000));\n",
    "plt.title('Retweet count')\n",
    "plt.xlabel('Retweets')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : \n",
    "The retweet seems to follow the similar pattern to favourite_count. Most of the tweets seems to be retweeted about 0 to 5000 times and only few tweets seems to cross this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which stage dogs has maximum tweets?\n",
    "\n",
    "dog_stage = df_twitter_master[df_twitter_master['dog_stage'] != \"None\"].dog_stage.value_counts()\n",
    "\n",
    "ax = (dog_stage).plot(kind='bar', title =\"Dog stages\", figsize=(15, 10), legend=True, fontsize=20)\n",
    "ax.set_xlabel(\"Stage\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: \n",
    "\n",
    "Most of the tweets are of dogs in stage ,\"pupper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which breed of dog seems to be most popular?\n",
    "\n",
    "\n",
    "breed = df_twitter_master[df_twitter_master['p1'] != \"None\"].p1.value_counts().head(20)\n",
    "\n",
    "ax = (breed).plot(kind='bar', title =\"Dog Breed Popularity\", figsize=(15, 10), legend=True, fontsize=20)\n",
    "ax.set_xlabel(\"breed\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "It seems golden retriever and labradors are really popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "After wrangling the data and combining all the data we were able to find many meaningful insights from the data.Such as the range of numbers of retweets and favourite we are likely to get. Also, we were able to find the most popular stage of dog and also the most popular breed of dogs.\n",
    "\n",
    "## Limitation:\n",
    "There are alot of insights we can draw out from the data than the insights drawn out in this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
